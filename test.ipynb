{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from utils.TSDataset import TimeSeriesDataset\n",
    "from utils.TSDataset import data_load\n",
    "from utils.plot import *\n",
    "from utils.split_train_val_test import *\n",
    "from utils.compute_metric import compute_metrics, append_score\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "project_dir\n",
    "\n",
    "data_path = os.path.join(project_dir, 'data', 'processed', 'BTC-USD-sample.csv')\n",
    "\n",
    "# Load data\n",
    "data1, x_scaler1, y_scaler1 = data_load(data_path, x_scaler='minmax', y_scaler='minmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Step Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizons = [1, 10, 30, 60]\n",
    "train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "scores = []\n",
    "target_col = 'y'\n",
    "\n",
    "test_target = test_df[target_col].values\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    naive_y_true = []  # will hold the true future values for every forecasting window\n",
    "    naive_y_pred = []  # will hold the corresponding naive predictions\n",
    "    \n",
    "    for i in range(len(test_target) - h):\n",
    "        # True values: for instance, at time step 0, this gets indices 1 to h (i.e., 1:11 when h=10)\n",
    "        y_true = test_target[i + 1: i + h + 1]\n",
    "        # Naive predictions: create an array of length h filled with the value at time step i\n",
    "        y_pred = np.full((h,), test_target[i])\n",
    "        \n",
    "        naive_y_true.append(y_true)\n",
    "        naive_y_pred.append(y_pred)\n",
    "    \n",
    "    naive_y_true = np.array(naive_y_true) \n",
    "    naive_y_pred = np.array(naive_y_pred) \n",
    "    \n",
    "    naive_y_true_flat = naive_y_true.flatten()\n",
    "    naive_y_pred_flat = naive_y_pred.flatten()\n",
    "    \n",
    "    naive_y_pred_flat = y_scaler1.inverse_transform(naive_y_pred_flat.reshape(-1, 1)).flatten()\n",
    "    naive_y_true_flat = y_scaler1.inverse_transform(naive_y_true_flat.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    mse_naive, mae_naive, huber_naive = compute_metrics(naive_y_true_flat, naive_y_pred_flat)\n",
    "    \n",
    "    # Print out the performance for this forecast horizon\n",
    "    record = {\n",
    "        'model': 'Naive',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_naive,\n",
    "        'mae': mae_naive,\n",
    "        'huber': huber_naive\n",
    "    }\n",
    "    append_score(scores, record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "target_col = 'y'\n",
    "feature_cols = ['x1', 'x2', 'x3', 'x4', 'x5']\n",
    "return_index = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    dense_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(window_size, len(feature_cols))),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    dense_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_dense = dense_model.fit(X_train, y_train, epochs=50,\n",
    "                                    validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    #plot_learning_curves(history_dense.history)\n",
    "    y_pred = dense_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_dense, mae_dense, huber_dense = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'Dense',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_dense,\n",
    "        'mae': mae_dense,\n",
    "        'huber': huber_dense\n",
    "    }\n",
    "    append_score(scores, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=20, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'Simple RNN',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=20, return_sequences=True, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.SimpleRNN(units=20, return_sequences=False),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'Deep RNN',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=20, return_sequences=True, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.SimpleRNN(units=20, return_sequences=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'RNN Batch Normalization',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(units=20, return_sequences=True, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.LSTM(units=20, return_sequences=False),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'LSTM',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(units=20, return_sequences=True, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.GRU(units=20, return_sequences=False),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'GRU',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Naive', 'h-step Forecast': 1, 'mse': 1160.3737790527032, 'mae': 25.10380253502343, 'huber': np.float32(24.65289)}\n",
      "{'model': 'Naive', 'h-step Forecast': 10, 'mse': 5275.257685590609, 'mae': 54.060173825503384, 'huber': np.float32(53.572155)}\n",
      "{'model': 'Naive', 'h-step Forecast': 30, 'mse': 13377.803699702954, 'mae': 85.68954353741499, 'huber': np.float32(85.19498)}\n",
      "{'model': 'Naive', 'h-step Forecast': 60, 'mse': 26082.668655180554, 'mae': 116.48661504629634, 'huber': np.float32(115.99019)}\n",
      "{'model': 'Dense', 'h-step Forecast': 1, 'mse': 7099.218512985851, 'mae': 64.98801944879484, 'huber': np.float32(64.49159)}\n",
      "{'model': 'Dense', 'h-step Forecast': 10, 'mse': 7384.670372438894, 'mae': 64.83106613071945, 'huber': np.float32(64.332886)}\n",
      "{'model': 'Dense', 'h-step Forecast': 30, 'mse': 14644.569688970922, 'mae': 90.51616048107792, 'huber': np.float32(90.017456)}\n",
      "{'model': 'Dense', 'h-step Forecast': 60, 'mse': 27024.345595480965, 'mae': 117.77280176794439, 'huber': np.float32(117.274025)}\n",
      "{'model': 'Simple RNN', 'h-step Forecast': 1, 'mse': 3803.8701294091447, 'mae': 51.09572396740335, 'huber': np.float32(50.596832)}\n",
      "{'model': 'Simple RNN', 'h-step Forecast': 10, 'mse': 6770.196501432811, 'mae': 62.53728895977536, 'huber': np.float32(62.039284)}\n",
      "{'model': 'Simple RNN', 'h-step Forecast': 30, 'mse': 14387.144091604408, 'mae': 88.53942296479005, 'huber': np.float32(88.040985)}\n",
      "{'model': 'Simple RNN', 'h-step Forecast': 60, 'mse': 30419.043968704365, 'mae': 127.01487326397763, 'huber': np.float32(126.51575)}\n",
      "{'model': 'Deep RNN', 'h-step Forecast': 1, 'mse': 4963.764295698104, 'mae': 60.00105068398057, 'huber': np.float32(59.50163)}\n",
      "{'model': 'Deep RNN', 'h-step Forecast': 10, 'mse': 7412.686035194483, 'mae': 65.74427326540973, 'huber': np.float32(65.24573)}\n",
      "{'model': 'Deep RNN', 'h-step Forecast': 30, 'mse': 14952.460689380676, 'mae': 92.19946085818654, 'huber': np.float32(91.700714)}\n",
      "{'model': 'Deep RNN', 'h-step Forecast': 60, 'mse': 27893.608429591433, 'mae': 121.74621956306981, 'huber': np.float32(121.247284)}\n",
      "{'model': 'RNN Batch Normalization', 'h-step Forecast': 1, 'mse': 17704.512387374114, 'mae': 108.96084578751774, 'huber': np.float32(108.462776)}\n",
      "{'model': 'RNN Batch Normalization', 'h-step Forecast': 10, 'mse': 11042.166114793703, 'mae': 83.07936708443661, 'huber': np.float32(82.58042)}\n",
      "{'model': 'RNN Batch Normalization', 'h-step Forecast': 30, 'mse': 19672.608875320042, 'mae': 106.25578825138783, 'huber': np.float32(105.757)}\n",
      "{'model': 'RNN Batch Normalization', 'h-step Forecast': 60, 'mse': 40258.689756106316, 'mae': 150.13974726378777, 'huber': np.float32(149.64043)}\n",
      "{'model': 'LSTM', 'h-step Forecast': 1, 'mse': 5758.5427616052, 'mae': 61.1819603085243, 'huber': np.float32(60.68343)}\n",
      "{'model': 'LSTM', 'h-step Forecast': 10, 'mse': 7796.9445677713375, 'mae': 66.63009193185503, 'huber': np.float32(66.131615)}\n",
      "{'model': 'LSTM', 'h-step Forecast': 30, 'mse': 16022.248736471298, 'mae': 95.18954389795317, 'huber': np.float32(94.690735)}\n",
      "{'model': 'LSTM', 'h-step Forecast': 60, 'mse': 28447.303857182185, 'mae': 122.0305723230749, 'huber': np.float32(121.53152)}\n",
      "{'model': 'GRU', 'h-step Forecast': 1, 'mse': 3022.378076762491, 'mae': 43.67200425277023, 'huber': np.float32(43.173565)}\n",
      "{'model': 'GRU', 'h-step Forecast': 10, 'mse': 6338.608621210473, 'mae': 59.776164098189874, 'huber': np.float32(59.278122)}\n",
      "{'model': 'GRU', 'h-step Forecast': 30, 'mse': 14360.91986155511, 'mae': 88.24483271802123, 'huber': np.float32(87.7463)}\n",
      "{'model': 'GRU', 'h-step Forecast': 60, 'mse': 26557.232854253252, 'mae': 117.24998910470343, 'huber': np.float32(116.750946)}\n"
     ]
    }
   ],
   "source": [
    "for i in scores:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
