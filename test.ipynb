{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from utils.TSDataset import TimeSeriesDataset\n",
    "from utils.TSDataset import data_load\n",
    "from utils.plot import *\n",
    "from utils.split_train_val_test import *\n",
    "from utils.compute_metric import compute_metrics, append_score\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "project_dir\n",
    "\n",
    "data_path = os.path.join(project_dir, 'data', 'processed', 'BTC-USD-sample.csv')\n",
    "\n",
    "# Load data\n",
    "data1, x_scaler1, y_scaler1 = data_load(data_path, x_scaler='minmax', y_scaler='minmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Step Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Naive', 'h-step Forecast': 1, 'mse': 1160.3737790527032, 'mae': 25.10380253502343, 'huber': np.float32(24.65289)}\n",
      "{'model': 'Naive', 'h-step Forecast': 10, 'mse': 5275.25768559061, 'mae': 54.060173825503384, 'huber': np.float32(53.572163)}\n",
      "{'model': 'Naive', 'h-step Forecast': 30, 'mse': 13377.803699702952, 'mae': 85.68954353741499, 'huber': np.float32(85.194984)}\n",
      "{'model': 'Naive', 'h-step Forecast': 60, 'mse': 26082.668655180554, 'mae': 116.48661504629631, 'huber': np.float32(115.99019)}\n"
     ]
    }
   ],
   "source": [
    "forecast_horizons = [1, 10, 30, 60]\n",
    "train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "scores = []\n",
    "target_col = 'y'\n",
    "\n",
    "test_target = test_df[target_col].values\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    naive_y_true = []  # will hold the true future values for every forecasting window\n",
    "    naive_y_pred = []  # will hold the corresponding naive predictions\n",
    "    \n",
    "    for i in range(len(test_target) - h):\n",
    "        # True values: for instance, at time step 0, this gets indices 1 to h (i.e., 1:11 when h=10)\n",
    "        y_true = test_target[i + 1: i + h + 1]\n",
    "        # Naive predictions: create an array of length h filled with the value at time step i\n",
    "        y_pred = np.full((h,), test_target[i])\n",
    "        \n",
    "        naive_y_true.append(y_true)\n",
    "        naive_y_pred.append(y_pred)\n",
    "    \n",
    "    naive_y_true = y_scaler1.inverse_transform(naive_y_true)\n",
    "    naive_y_pred = y_scaler1.inverse_transform(naive_y_pred)\n",
    "    mse_naive, mae_naive, huber_naive = compute_metrics(naive_y_true, naive_y_pred)\n",
    "    \n",
    "    # Print out the performance for this forecast horizon\n",
    "    record = {\n",
    "        'model': 'Naive',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_naive,\n",
    "        'mae': mae_naive,\n",
    "        'huber': huber_naive\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "for i in scores:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "target_col = 'y'\n",
    "feature_cols = ['x1', 'x2', 'x3', 'x4', 'x5']\n",
    "return_index = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    dense_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(window_size, len(feature_cols))),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    dense_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_dense = dense_model.fit(X_train, y_train, epochs=50,\n",
    "                                    validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    #plot_learning_curves(history_dense.history)\n",
    "    y_pred = dense_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_dense, mae_dense, huber_dense = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'Dense',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_dense,\n",
    "        'mae': mae_dense,\n",
    "        'huber': huber_dense\n",
    "    }\n",
    "    append_score(scores, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=20, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'Simple RNN',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    scores.append(record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=20, return_sequences=True, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.SimpleRNN(units=20, return_sequences=False),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'Deep RNN',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=20, return_sequences=True, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.SimpleRNN(units=20, return_sequences=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'RNN Batch Normalization',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(units=20, return_sequences=True, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.LSTM(units=20, return_sequences=False),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'LSTM',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeddyxie/CNN-LSTM/CNN-LSTM/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "(1441, 10)\n",
      "[0.22915536 0.21745737 0.2389725  0.22488208 0.21692193 0.23346631\n",
      " 0.23073803 0.25786266 0.22497006 0.22984926]\n",
      "[12781.507]\n",
      "[12812.77999632]\n",
      "8071.985366673137\n",
      "70.98088142615924\n",
      "70.48248\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "forecast_horizons = [10]\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "    rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(units=20, return_sequences=True, input_shape=(window_size, len(feature_cols))),\n",
    "    tf.keras.layers.GRU(units=20, return_sequences=False),\n",
    "    tf.keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    rnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = rnn_model.fit(X_train, y_train, epochs=3,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = rnn_model.predict(X_test)\n",
    "\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    print(mse_rnn)\n",
    "    print(mae_rnn)\n",
    "    print(huber_rnn)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'GRU',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "{'model': 'CNN-LSTM', 'h-step Forecast': 1, 'mse': 1776.0033139586972, 'mae': 32.65602552087393, 'huber': np.float32(32.15984)}\n",
      "{'model': 'CNN-LSTM', 'h-step Forecast': 10, 'mse': 6122.235423251777, 'mae': 58.971645334105524, 'huber': np.float32(58.473972)}\n",
      "{'model': 'CNN-LSTM', 'h-step Forecast': 30, 'mse': 15892.558204614965, 'mae': 93.31983408544221, 'huber': np.float32(92.82109)}\n",
      "{'model': 'CNN-LSTM', 'h-step Forecast': 60, 'mse': 26614.687826459573, 'mae': 117.01620187787084, 'huber': np.float32(116.51741)}\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "forecast_horizons = [1, 10, 30, 60]\n",
    "for h in forecast_horizons:\n",
    "    train_df, test_df = split_train_val_test(data1, train_frac=0.7)\n",
    "    train_set = TimeSeriesDataset(dataframe=train_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "    test_set = TimeSeriesDataset(dataframe=test_df, window_size=window_size, forecast_horizon=h, feature_cols=feature_cols, target_col=target_col, return_index=return_index)\n",
    "\n",
    "    X_train, y_train, x_dates, y_dates = train_set.X_seq, train_set.y_seq, train_set.x_dates, train_set.y_dates\n",
    "    X_test, y_test, x_dates_test, y_dates_test = test_set.X_seq, test_set.y_seq, test_set.x_dates, test_set.y_dates\n",
    "\n",
    "   \n",
    "    cnn_model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(window_size, len(feature_cols))),\n",
    "    keras.layers.Conv1D(filters=16, kernel_size=2, padding=\"valid\"),\n",
    "    keras.layers.LSTM(32, return_sequences=True),\n",
    "    keras.layers.LSTM(32, return_sequences=False),\n",
    "    keras.layers.Dense(h)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.004717880792838919)\n",
    "    cnn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "    history_rnn = cnn_model.fit(X_train, y_train, epochs=20,\n",
    "                                validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_pred = cnn_model.predict(X_test)\n",
    "    y_pred = y_scaler1.inverse_transform(y_pred.reshape(-1, 1))\n",
    "    y_true = y_scaler1.inverse_transform(y_test.reshape(-1, 1))\n",
    "    \n",
    "    mse_rnn, mae_rnn, huber_rnn = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    record = {\n",
    "        'model': 'CNN-LSTM',\n",
    "        'h-step Forecast': h,\n",
    "        'mse': mse_rnn,\n",
    "        'mae': mae_rnn,\n",
    "        'huber': huber_rnn\n",
    "    }\n",
    "    append_score(cnn_lstm_scores, record)\n",
    "    #plot_learning_curves(history_rnn.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
